# 2020 中间件性能挑战赛“ServiceMesh”题目——控制面分治体系构建 🎊

### 问题背景
阿里拥有成百万级别的服务实例。虽然经过早先努力，阿里 Nacos 解决了超大规模服务发现问题，但服务网格的先行者 Istio 却一直是单体全量数据，不能横向扩容。因此我们找个办法，通过让不同的 Pilot 实例负责不同的 Sidecar——即分治方式——来支撑超大规模的系统；然而这里的一个挑战是：如何分配 Sidecar 才能让 Pilot 集群整体负载均衡 ？


为了更好地说明问题，我们先将问题简化成以下模型：


![image.png](https://img.alicdn.com/tfs/TB1spuDDBv0gK0jSZKbXXbK2FXa-857-909.png)

_图1_ 
<br/>
<br/>

这里说明如下：

- 三个部分，从上至下分别是：注册中心、Pilot 集群以及应用（左侧花括号中为应用依赖的服务，中间为应用实例对应的 Sidecar）；
- 每个应用中 Sidecar 依赖的服务都是一样的，不同应用依赖的服务可能有重叠；
- 应用可能随时增减、应用的 Sidecar 也可能随时增减；
- 每个 Pilot 依据连接上来的 Sidecar 实例需要的全部服务，向注册中心发起服务订阅，将结果存于内存中并推送给他们。



由此可见，Pilot 单个实例承压为：Sidecar 连接量 + 服务数据。服务数据越大，意味着推送前处理的数据越多；连接数越多，意味着需要推送的数据越多。因此，这里的性能优化便成了设法降低这两个值，这体现在 Pilot 集群里便是让 Sidecar 连接更均匀，以及减少 Pilot 服务加载的重复度。但这并不简单，因为我们尝试优化一个时，另一个就会变差。例如，如果我们采取随机连接的方式，那么 Sidecar 连接将会比较平均，单个实例的连接数便较小，但每个 Pilot 加载的服务量增加，因为加载的是 Sidecar 依赖的并集；

![image.png](https://img.alicdn.com/tfs/TB1PAqGDxv1gK0jSZFFXXb0sXXa-815-903.png)

_图2_
<br/>
<br/>

如果我们采用散列函数按服务依赖映射至 Pilot，单个实例加载的服务会减少，但是多个应用可能会映射到同一 Pilot，连接数又会增加，造成不均匀问题（如图2所示）。


### ![image.png](https://img.alicdn.com/tfs/TB1MVuDDBv0gK0jSZKbXXbK2FXa-875-927.png)

_图3_
<br/>
<br/>

所以，我们需要寻找一个最优解。


### 问题描述
首先我们简化问题，只在**应用维度**进行 Sidecar 分配，同时为了更好的地理解问题，我们进行以下抽象：

- 已知：
  - 提供一个应用列表 A，以及每个应用对应的 Sidecar 数量 n；
  - 对于每个应用 a，提供一个服务依赖列表 D；
  - 已知一个 Pilot 集群，并有 m 个实例。
- 条件：
  - 为了保障 Sidecar 由访问的顺畅，防止惊群，在整个过程中 Pilot 的加载的服务只增不减（即使应用迁移到其它 Pilot 上，加载的数据依然存在），请谨慎调整应用连接的 Pilot；
  - 需要支持应用增减，Sidecar 扩容、缩容，变化后每个 Sidecar 需要的服务需要在对应的 Pilot 上找到，不得缺失。
- 求：
  - 每个 Pilot 实例需要挂载的应用列表 Pi(L)（i ∈ [0, m-1]）。



### 评估标准
统计 Pilot 集群内存使用总量以及每个实例内存占用标准差（检测标准差的目的是为了让 Pilot 的内存更加均匀，避免出现个例情况，意味着算法更具备生产意义）与 Sidecar 挂载数量的标准差，最终的计算公式为：

得分 = ![](https://cdn.nlark.com/lark/__latex/9900a6ee1f60a607f7efbe1f08514617.svg#card=math&code=%5Cfrac%7BM_%7B%E5%8A%A0%E8%BD%BD%E5%86%85%E5%AD%98%7D%7D%7BM_%7B%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98%7D%7D%20%5Ccdot%20%28Dif_%7B%E5%86%85%E5%AD%98%E6%A0%87%E5%87%86%E5%B7%AE%7D%20%2B%20Dif_%7B%E8%BF%9E%E6%8E%A5%E6%A0%87%E5%87%86%E5%B7%AE%7D%29&height=54&width=284)

其中：

- ![](https://cdn.nlark.com/lark/__latex/d9616f16d9b0fa83936a5c770ad1217f.svg#card=math&code=M_%7B%E5%8A%A0%E8%BD%BD%E5%86%85%E5%AD%98%7D&height=24&width=62) 指所有 Pilot 实际加载的内存，我们按每个节点占用 0.01 的方式估计。例如某 Pilot 加载了两个应用，其依赖的服务分别为  [srv1:30, srv2:60]、[srv1: 30, srv3: 25]，则其加载的总服务为 [srv1:30, srv2: 60, srv3: 25], 其对应的节点总合为 115，因此占用的内存为 1.15；
- ![](https://cdn.nlark.com/lark/__latex/856375f0207701127a791ab6bd86982a.svg#card=math&code=M_%7B%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98%7D&height=24&width=62) 指提供的数据中全部服务所占用的内存总量，其计算方式与加载内存一致；
- ![](https://cdn.nlark.com/lark/__latex/4ab944acf51a3cc08f05ac3d3b3f7a02.svg#card=math&code=Dif_%7B%E5%86%85%E5%AD%98%E6%A0%87%E5%87%86%E5%B7%AE%7D&height=24&width=85) 指全部 Pilot 加载内存的标准差；
- ![](https://cdn.nlark.com/lark/__latex/fcecb1289fe4c1b0f44182e8e9fd9425.svg#card=math&code=Dif_%7B%E8%BF%9E%E6%8E%A5%E6%A0%87%E5%87%86%E5%B7%AE%7D&height=24&width=85) 指全部 Pilot 的 Sidecar 连接的标准差，Sidecar 的连接是由应用挂载决定的，例如某 Pilot 承载两个应用 {app1: 40, app2: 20}，因此其 Sidecar 的挂载为 60；



得分越小者，总成绩越好。

<br/>

按以上标准需要评估二轮，一是在首批 Pilot 及 Sidecar 启动后的成绩；第二轮是动态增加一批应用后的成绩，两者剩以 50% 相加为最终成绩。

<br/>

例如：提供数据中服务应总内存 1000，选手 A 的算法部署后，3 台 Pilot 的总内存为 1245，内存标准差为 10.3，连接标准差为 15.15；经过一系列的变化后，其内存变为 1812, 服务加载标准差为 14.5，Sidecar 连接标准差为  12.1，则其总得分为：

_得分 = 0.5 * [1.245*25.45] + 0.5 * [1.812*26.6] =_ 39.9422‬（精确到 4 位小数）

<br/>

本次测评使用评分程序进可以提前提供给参赛选手。每个阶段均有时间限制，超过视为成绩无效。
### 本地测试环境搭建
请参考此处[文档](https://code.aliyun.com/middleware-contest-2020/pilotset/blob/master/LOCAL_DEV.md)

### 机器参数
线上评分中，容器的处理器与内存为 4C2G（即 4 个核心，2GiB 的内存数量），磁盘大小 10GiB 限制，无 GPU 加速，无网络访问能力，Docker 镜像限制大小为 1GiB。 <br />
_这里需要要特别注意的是：选手的运行环境使用 Docker 软性隔离，因此如果使用如 Java 获取 CPU 与 内存大小时会不准，如有需要请手动指定。_
### 输入数据
_数据一，应用列表 A 及每个应用的 Sidecar个数 n：_

采用 JSON 形式给出，格式为 {"app-name": node-count, ...}，例：{"app-1": 5, "app-2": 6, "app-3": 10}。

<br/>

_数据二，对于每个应用，提供一个服务依赖列表 S：_

采用 JSON 形式给出，格式为 {"app-name":{"service-identifier", node-count, ...}，例：{"app-1" : {"srv1": 10, "srv2": 30, "srv3": 10, "srv10": 15}, "app-2" : {"srv3": 10, "srv4": 8, "srv5": 12}, ......}。

以上两种数据存储在名为 data.json 中，为一个 Map 结构，对应的 Key 分别为 apps 以及 dependencies，如：
{"apps": {"app-1": 5, "app-2": 6, "app-3": 10, ……}, "dependencies": {"app-1" : {"srv1": 10, "srv2": 30, "srv3": 10, "srv10": 15}, "app-2" : {"srv3": 10, "srv4": 8, "srv5": 12}, ......}}
。data.json 存放在容器的 /root/input 目录下。

<br/>

_数据三，Pilot 集群列表：_

采用 JSON 形式给出，格式为 {"pilots": ["pilot-indentifier"......]}，例：{"pilots": ["p1", "p2", "p3",......]}。

数据三会在评测的时候通过 HTTP 请求发送过来，详见下面的评测方法部分。

<br />

_注意：以上三种数据均是无法提前获取到的，线上评测时，会实时提供且数据量很大，但数据由额外磁盘挂入，不计入镜像大小。每次评测输入的数据不一定相同，但成绩只以最后一次为准，主办方可以随时要求选手程序重测。在答辩的时候，需要提供源码及逻辑分析，无法自明的逻辑算作无效成绩。_
### 输出数据

_数据一，每个 Pilot 需要挂载的应用列表：_

采用 JSON 形式给出，格式为：{"pilot-identifier" : ["app-name", ...]}，例：{"p1": ["app-1", "app-2", "app-3"], "p2": ["app-4"],......]}。
注意每个 app 只能被分配至一个 pilot，重复分配将导致无效评分。

### 评测方法
在评测将分为两个阶段。评分程序与选手应用的对接方式采用 HTTP 接口的形式，选手需要提供三个 HTTP 接口：

1. HTTP 1.1 HEAD localhost:3355/ready：一个状态接口，启动时评分程序会对探测，返回 HTTP 200 即表示选手的程序已经就绪，可以执行后续操作，接口 1；
1. HTTP 1.1 POST localhost:3355/p1_start：第一阶段的启动接口；
1. HTTP 1.1 POST localhost:3355/p2_start：第二阶段的启动接口。

<br/>

评分程序与选手的程序在两个不同的容器中运行，但都属于同一个 Pod。选手需要将自己的程序打包成 Docker 镜像并配置好执行入口与磁盘挂载点 /root/input，线上评测时会提供磁盘卷挂入 /root/input，并在 /root/input 目录下放置上述比赛需要的文件，数据在需要的时候才会生成，不能提前获取。

- 评分程序首先会访问“接口1”以确定选手的应用程序已经准备就绪，准备时间不得超过 10 秒。检测通过后会在选手容器的 /root/input 目录下放置评测使用的 data.json 供选开始数据分析。
- 然后通过 “接口2” 向选手提供 Pilot 的列表，数据格式如“输入数据三”一致。表单格式为 “Content-Type: application/json;charset=utf-8 ” 即 JSON 形式，参数放置在 Body 中。当“接口2” HTTP 请求返回时即视为选手已经处理完一阶段的数据，此时停止一阶段计时，HTTP 接口返回的是“输出数据一”。评分程序收到后便按上述标准进行评分。“接口2” 的超时时间为 2 分钟，超时全过程得分无效；评分程序接受一次结果，后续更新无效。
- 在第二阶段中，评分程序通过调用“接口3”，动态增加应用，数据格式与 data.json 一致。表单格式为 “Content-Type: application/json;charset=utf-8 ” 即 JSON 形式，参数放置在 Body 中，。在 HTTP 返回 200 ，也需要返回 “输出数据一” 要求的格式——注意这里返回必须包含阶段一的应用。所有新增轮完成以后，评分程序会检查依赖加载是否正确。每轮更新，“接口3” 的超时时间为 15 秒，超时全过程得分无效。

<br/>

当两个阶段的评分都产出以后，评分程序会按之前定义的标准输出最终评分供选手排名。
